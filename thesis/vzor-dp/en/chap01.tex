\chapter{Machine Learning: Overview}
\section{The Basics}


An agent is something that acts. A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome. Any component of an agent can be improved by learning from data. The improvements and techniques used to make them depend on four major factors:

\begin{itemize}
  \item Which component is to be improved.
  \item What prior knowledge the agent already has.
  \item What representation is used for the data and the component.
  \item What feedback is available to learn from.  
\end{itemize}

Here we will mostly be focused on the final point, "What feedback is available to learn from." but also slightly on the second point because we will incorporate Bayesian learning. There are three main types of feedback that determine the three main types of learning which are unsupervised, reinforcement, and supervised learning. 

In unsupervised learning an agent learns patterns even though no feedback is provided. In reinforcement learning, the agent learns from a series of rewards or punishments. In supervised learning, an agent learns from input-output pairs, which can be discrete or continuous, to find a function that maps the pairs. 

The goal of supervised learning is given a training set of $N$ example input-output pairs:

\[(x_1, y_1), (x_2,y_2),... (x_N,y_N),\]

where each $y_j$ was generated by some unknown function $y=f(x)$, find a function $h$ that approximates the true function
(\cite{russell2009artificial}).

In reality, the lines separating the types of learning aren't so clear. Semi-supervised learning is also an important and widely used method. In semi-supervised learning we are given a few labeled examples and must make the most of a large collection of unlabeled examples. 

\section{Active Learning}

Supervised learning models almost always get more accurate with more labeled data. Active learning is the process of deciding which data to sample for human annotation. Many active learning strategies exist, but three basic approaches work well in most contexts: uncertainty, diversity, and random sampling. A combination of the three is usually a good starting point. 

It should be noted that we can sample $n$ candidates where $n >= 1$ depending on our preferences.

\subsection{Random Sampling}

Random sampling is rather self explanatory as we randomly select an unlabeled data point from the pool and have a human provide a label.

\subsection{Diversity Sampling}

Diversity sampling is the set of strategies for identifying unlabeled items that are underrepresented or unknown to the machine learning model in its current state. The items may have features that are unique or obscure in the training data, or they might represent data that are currently under-represented in the model. Either way this can result in poor or uneven performance when the model is applied or the data is changing over time. The goal of diversity sampling is to target new, unusual, or underrepresented items for annotation to give the algorithm a more complete picture of the problem space. 

\subsection{Uncertainty Sampling}

Uncertainty sampling is the set of strategies for identifying unlabeled items that are near a decision boundary in your current machine learning model. If you have a binary classification task, these items will have close to a 50\% probability of belonging to either label; therefore, the model is called uncertain or confused. These items are most likely to be wrongly classified, so they are the most likely to result in a label that differs from the predicted label, moving the decision boundary after they have been added to the training data and the model has been retrained (\cite{munro2021human}).

\subsection{Bayesian Learning}

\subsection{Expected Error Reduction}

\subsection{Summary}

After we select and label the candidate data we retrain the model with the updated data and we continue this process as new data is obtained or until we are satisfied with the performance of the model


