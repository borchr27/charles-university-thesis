\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

The entire process of data collection, storage, retrieval, processing, and testing allowed us to create a customized pipeline and explore active learning using website text data to classify online merchants and other websites. The quality of the collected data wasn't perfect but we were able to use the data to create a model that could classify websites into 1 of 23 categories with $\sim$60\% accuracy using a linear support vector classifier. We also discovered that the xPAL sampling strategy discovered the best samples quickly to reduce the testing error the most.

Pairing an optimal classifier with xPAL allows us to create a pipeline to choose the most informative data points to add to the training set and reduce the amount of time it takes to train the model as well as the size of the classifier.

Many sites had multiple languages present on their websites and this could be seen in our scraped data. This posed a challenge for us because when using the API for translation it made it more difficult to detect the language while also adding non english words into the TF-IDF.

\section*{Improvements}

To improve the results of the active learning classifier we would suggest making a number of changes. One of the first changes would be to find a better way to profile a website and make sure the quality of the text data from the websites were better. For example, a stronger web scraper would have allowed us to avoid potential IP address restriction issues and scrape data from social media websites that refused to allow our scraper to collect any data and resulted in some unusable data. We could have also run our own tests regarding how the number of sibling pages could have fortified the data.

The scraper could be designed to scrape multiple pages of a website, scrape social media pages, and possibly scrape other websites that are linked to the original website. This could improve the quality of the data and allow for more accurate classification. Prioritizing the quality of the data is one of the key points to improving the performance of the classifier. It also seems that a small amount of good text data is better than a large amount of poor quality text data. Another way we could have made the scraped data better for the classifier is to take out all non english words (post translation).

To be more thorough, we could have run exhaustive tests for \textit{all} the available classifiers within Scikit-Learn using GridSearchCV and other ensemble methods to see if any more performance gains were attainable. We could have also explored the performance of TensorFlow RNN's and LTSM's for text classification.

The current setup of the active learning xPAL process uses the PWC as it is fast (because it updates only parts of the classifier with each new data point) and relatively simple to implement. However, it is not the best method for classifying our data as we have seen from our experiments. We could improve the pipeline by implementing xPAL with other Scikit-Learn classifiers and running tests to choose the best active learning classifier for our data.

