\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

One of the main challenges of creating a successful machine learning model is obtaining labeled data. With easy access to a variety of modern tools, devices, and sensors, we are able to rapidly collect unlabeled data. But, in supervised learning, prediction models are trained using labeled data. The problem is that acquiring labels for the collected data can be expensive, time-consuming, or even impossibly difficult in some cases.  

However, methods have been developed to help reduce the number of labeled data required to train the classifier. Active learning is a semi-supervised machine learning framework where the model is trained with a smaller set of labeled data but which also aims to exploit trends within the unlabeled data. Active learning is a framework in which the learner has the freedom to select which data points are added to its training set (\cite{roy2001eer}). 

Active learning is different from other frameworks because it uses the unlabeled data and some evaluation criteria to determine which candidate could be the most beneficial to the model if it was given a label. In summary, the model requests the label from some oracle that provides the label then it takes this new labeled data point and rebuilds the classifier. We describe it as semi supervised active learning because of the oracle (typically a human) involved in the process that provides the label for the requested candidate data. 

In our case we will provide a set of labeled data to the active learning framework (or sampling strategy). The sampling strategy will assume all the data is unlabeled and then choose a candidate from the unlabeled data pool. Then the label is revealed and the classifier is updated using the new data point. The newly labeled data point is then added to the labeled data pool and the process repeats.

We have some data (website urls) for some company or business that are given to us from our partner. From this data our partner currently utilizes human labor to browse the website and then label the url with a category (23 labels) and a sub-category (~234+ tags) that branch from the main category but still have some relation. This is a repetitive and expensive task that could be supplemented using active learning.

To reduce the amount of data required to train the classifier we consider a combination of tools and frameworks, namely: Scrapy, Postgres, a translation service, and an active learning sampling strategy paired with a classifier. We also explore the use of different classifiers to determine if there is some optimal classifier.

A website is required as input, then we use the Scrapy framework to navigate to the webpage, and collect then store the scraped data into the database. Next we access the data, translate the text, and add the translated data back into the database. During this process we also remove some html tags and other unnecessary data.

Once the the data is close to just pure text we use TF-IDF to transform it into a vectorized representation. This data is used by the active learning sampling strategy and the model is trained iteratively. We also explore different classifiers to determine if there is some optimal classifier other than the one implemented within the sampling strategy framework.

In the first section we introduce active learning and the different components of active learning. In the second section we look more into the details of xPAL and how it works. In the third section we discuss the data and the steps we took to collect and process the data. In the fourth section we conduct a variety of experiments to explore the performance of the sampling strategies and alternative classifiers. 

Our goal is to understand the entire process including the web scraping, translation, storing, and performance of the selection strategies and classifiers. This analysis will allow our partner to learn from our tests and experiments. It will also allow them to make an informed decision on which models and selection strategies may be best suited for their needs moving forward.

\section*{Notable Definitions}

In this section we define some terms and ideas that will be helpful in understanding the upcoming sections.

\begin{defn}[Beta Prior]
\label{def:beta_prior}
A beta prior is a conjugate prior for the binomial distribution. It is a continuous probability distribution defined on the interval [0, 1] and is parameterized by two positive shape parameters, \(\alpha\) and \(\beta\). The beta distribution is defined as: 
\[\text{Beta}(\alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha - 1}(1 - x)^{\beta - 1}\]
where \(\Gamma\) is the gamma function and \(x\) is a random variable. The gamma function is defined as:
\[\Gamma(x) = \int_0^\infty t^{x - 1}e^{-t}dt\]
The gamma function is used as a normalizing constant to ensure that the probability density function integrates to 1 over the simplex, which is the space of all probability vectors that sum to 1.
\end{defn}

\begin{defn}[Conjugate Prior]
\label{def:conjugate_prior}
A conjugate prior is a prior distribution that is in the same family of distributions as the likelihood function. In other words, the posterior distribution will have a similar functional form to the prior distribution.
\end{defn}

\begin{defn}[Decision-Theoretic]
\label{def:decision_theoretic}
Decision-theoretic active learning is a framework that uses the expected performance gain of a candidate to determine which candidate to label. The expected performance gain is the expected performance of the classifier after labeling the candidate minus the expected performance of the classifier before labeling the candidate. The expected performance of the classifier is the expected value of the performance measure given the posterior distribution of the classifier.
\end{defn}

\begin{defn}[Dirichlet Distribution]
\label{def:dirichlet_distribution}
The Dirichlet distribution is a multivariate generalization of the beta distribution. It is a continuous probability distribution defined on the \(K\)-simplex, \(\Delta_K = \{x \in \mathbb{R}^K: x_i \geq 0, \sum_{i=1}^K x_i = 1\}\). The Dirichlet distribution is parameterized by a vector of positive shape parameters, \(\alpha = (\alpha_1, \alpha_2, \dots, \alpha_K)\). The Dirichlet distribution is defined as:
\[\text{Dir}(\alpha) = \frac{\Gamma(\sum_{i=1}^K \alpha_i)}{\prod_{i=1}^K \Gamma(\alpha_i)}\prod_{i=1}^K x_i^{\alpha_i - 1}\]
where \(\Gamma\) is the gamma function as defined in Definition \ref{def:beta_prior} and where \(x\) is a random vector.
\end{defn}

\begin{defn}[Ground Truth]
\label{def:ground_truth}
Ground truth is the true label of a data point.
\end{defn}

\begin{defn}[Posterior Probabilities]
\label{def:posterior_probabilities}
Posterior probability is a type of conditional probability that results from updating the prior probability with information summarized by the likelihood via an application of Bayes' rule. The posterior probability is the probability of an event occurring given that another event has occurred.
\end{defn}

\begin{defn}[Omniscient Oracles]
\label{def:omniscient_oracles}
Omniscient oracle is a hypothetical entity that has complete knowledge of the true labels of all data points in a given dataset. An omniscient oracle knows the ground truth labels of all data points.
\end{defn}

\begin{defn}[TF-IDF]
\label{def:tf_idf}
TF-IDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining. The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus (large structured set or collection of speech or text data).
\end{defn}